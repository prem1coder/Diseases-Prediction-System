{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d013fdda",
      "metadata": {},
      "source": [
        "# Liver Disease Dataset EDA\n",
        "This notebook performs exploratory data analysis (EDA) on the liver disease dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7bf794c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24129951",
      "metadata": {},
      "source": [
        "## Load the Dataset\n",
        "Load the liver disease dataset for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc1254c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "print(\"Files in current directory:\")\n",
        "print(os.listdir())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "file_load_cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset from the workspace\n",
        "try:\n",
        "    df = pd.read_csv('Liver Patient Dataset (LPD)_train.csv')\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "    display(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(\"Dataset file not found. Please check the file path.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18b7e015",
      "metadata": {},
      "source": [
        "## Dataset Overview\n",
        "Check the shape, columns, and basic info of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "overview_cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset shape and info\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nColumn Names:\")\n",
        "print(df.columns.tolist())\n",
        "print(\"\\nDataset Info:\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "quality_check_cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Types and Quality Check\n",
        "print(\"Data Types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nUnique values per column:\")\n",
        "for col in df.columns:\n",
        "    print(f\"{col}: {df[col].nunique()} unique values\")\n",
        "\n",
        "# Check for any potential data quality issues\n",
        "print(\"\\nData Quality Check:\")\n",
        "print(f\"Total rows: {len(df)}\")\n",
        "print(f\"Total columns: {len(df.columns)}\")\n",
        "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
        "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
        "\n",
        "# Handle any 'Gender' column encoding if present\n",
        "if 'Gender' in df.columns:\n",
        "    print(f\"\\nGender distribution:\")\n",
        "    print(df['Gender'].value_counts())\n",
        "    \n",
        "# Check for any unusual values or outliers\n",
        "print(\"\\nBasic statistics for numeric columns:\")\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "if len(numeric_cols) > 0:\n",
        "    print(df[numeric_cols].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "stats_header",
      "metadata": {},
      "source": [
        "## Statistical Summary\n",
        "Get a statistical summary of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stats_cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary\n",
        "print(\"Statistical Summary:\")\n",
        "display(df.describe())\n",
        "\n",
        "# For categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "if len(categorical_cols) > 0:\n",
        "    print(\"\\nCategorical columns summary:\")\n",
        "    for col in categorical_cols:\n",
        "        print(f\"\\n{col}:\")\n",
        "        print(df[col].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "missing_header",
      "metadata": {},
      "source": [
        "## Check for Missing Values\n",
        "Identify missing values in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "missing_cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Missing values analysis\n",
        "missing_data = df.isnull().sum()\n",
        "missing_percent = (missing_data / len(df)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': missing_data,\n",
        "    'Percentage': missing_percent\n",
        "}).sort_values('Missing Count', ascending=False)\n",
        "\n",
        "print(\"Missing Values Summary:\")\n",
        "print(missing_df[missing_df['Missing Count'] > 0])\n",
        "\n",
        "# Visualize missing values if any\n",
        "if missing_data.sum() > 0:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    missing_data[missing_data > 0].plot(kind='bar')\n",
        "    plt.title('Missing Values by Column')\n",
        "    plt.xlabel('Columns')\n",
        "    plt.ylabel('Missing Value Count')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No missing values found in the dataset!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "viz_header",
      "metadata": {},
      "source": [
        "## Visualize Feature Distributions\n",
        "Visualize the distribution of key features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "age_viz_cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize Age distribution\n",
        "if 'Age' in df.columns:\n",
        "    plt.figure(figsize=(10,6))\n",
        "    sns.histplot(df['Age'], kde=True, bins=30)\n",
        "    plt.title('Age Distribution')\n",
        "    plt.xlabel('Age')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Age column not found in the dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bilirubin_viz_cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize Total Bilirubin distribution\n",
        "if 'Total_Bilirubin' in df.columns:\n",
        "    plt.figure(figsize=(10,6))\n",
        "    sns.histplot(df['Total_Bilirubin'], kde=True, bins=30)\n",
        "    plt.title('Total Bilirubin Distribution')\n",
        "    plt.xlabel('Total Bilirubin')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Total_Bilirubin column not found in the dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "corr_header",
      "metadata": {},
      "source": [
        "## Correlation Heatmap\n",
        "Visualize correlations between features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "corr_cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select only numeric columns for correlation analysis\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if len(numeric_cols) > 1:\n",
        "    plt.figure(figsize=(12,10))\n",
        "    correlation_matrix = df[numeric_cols].corr()\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "                square=True, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
        "    plt.title('Feature Correlation Heatmap (Numeric Features Only)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print highly correlated pairs\n",
        "    print(\"\\nHighly correlated feature pairs (|correlation| > 0.7):\")\n",
        "    for i in range(len(correlation_matrix.columns)):\n",
        "        for j in range(i+1, len(correlation_matrix.columns)):\n",
        "            corr_val = correlation_matrix.iloc[i, j]\n",
        "            if abs(corr_val) > 0.7:\n",
        "                print(f\"{correlation_matrix.columns[i]} - {correlation_matrix.columns[j]}: {corr_val:.3f}\")\n",
        "else:\n",
        "    print(\"Not enough numeric columns for correlation analysis.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary_header",
      "metadata": {},
      "source": [
        "## Summary\n",
        "Key findings from the exploratory data analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "summary_cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary of key findings\n",
        "print(\"=== EDA SUMMARY ===\")\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "print(f\"Number of Features: {len(df.columns)}\")\n",
        "print(f\"Number of Samples: {len(df)}\")\n",
        "print(f\"\\nData Types:\")\n",
        "print(df.dtypes.value_counts())\n",
        "print(f\"\\nMissing Values: {df.isnull().sum().sum()}\")\n",
        "print(f\"Duplicate Rows: {df.duplicated().sum()}\")\n",
        "\n",
        "# Memory usage\n",
        "print(f\"\\nMemory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "print(\"\\n=== RECOMMENDATIONS ===\")\n",
        "print(\"1. Check for and handle missing values if any\")\n",
        "print(\"2. Consider feature scaling for machine learning models\")\n",
        "print(\"3. Look for outliers in numeric features\")\n",
        "print(\"4. Consider feature engineering based on domain knowledge\")\n",
        "print(\"5. Ensure proper encoding of categorical variables\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
